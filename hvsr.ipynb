{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----Importing necessary stuff----\n",
    "import os  # Handling filesystems\n",
    "import warnings\n",
    " \n",
    "# Ignoring a silly warning from HVSRPY\n",
    "warnings.simplefilter(\"ignore\", UserWarning) \n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning) \n",
    "\n",
    "import numpy as np  # Numerical array management\n",
    "import matplotlib.pyplot as plt  # Plot results\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import spines\n",
    "from tqdm import tqdm  # To track progress of HVSR computations\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal.windows import hann\n",
    "from scipy.integrate import romb, cumulative_simpson, simpson\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['date.converter'] = 'concise'\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "\n",
    "from obspy.clients.filesystem.sds import Client  # Locally stored data\n",
    "from obspy import read, read_inventory, UTCDateTime  # Creating datetime objects\n",
    "\n",
    "import hvsrpy  # Dear goodness\n",
    "from hvsrpy import preprocess, process, TimeSeries, SeismicRecording3C, settings, sesame\n",
    "from hvsrpy import frequency_domain_window_rejection as window_rejection\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = '/Users/roberto/Documents/colima-data/sds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = read_inventory('/Users/roberto/Documents/colima-data/response/MNGR.xml')\n",
    "for canal in inv[0][0]:\n",
    "    canal.location_code = '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----Setting up OBSPY client----\n",
    "client = Client(sds)\n",
    "net = 'UC'  # Universidad de Colima\n",
    "sta = 'MNGR'  # Montegrande\n",
    "loc = '00'\n",
    "cha = 'HH*'  # Every broadband channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = client.get_waveforms(net, sta, loc, cha, UTCDateTime(2015,1,1), UTCDateTime(2015,1,2))\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----Setting up HVSRPY----\n",
    "freq1 = 1\n",
    "freq2 = 25\n",
    "nfreqs = 200\n",
    "freqs = np.geomspace(freq1,freq2,nfreqs)\n",
    "\n",
    "# Preprocessing (detrend, window length, bandpass filter)\n",
    "preproc = settings.HvsrPreProcessingSettings()  # Init \n",
    "preproc.detrend = 'linear'\n",
    "preproc.window_length_in_seconds = 60  # why no overlap?\n",
    "preproc.filter_corner_frequencies_in_hz = [0.1, 49.0]\n",
    "print('-'*60)\n",
    "print('Preprocessing Summary')\n",
    "print('-'*60)\n",
    "preproc.psummary()\n",
    "\n",
    "# Processing for traditional HVSR\n",
    "proc = settings.HvsrTraditionalProcessingSettings()  # Init\n",
    "proc.window_type_and_width = ('tukey', 0.2)\n",
    "proc.smoothing = dict(operator = 'konno_and_ohmachi',\n",
    "                      bandwidth = 40,\n",
    "                      center_frequencies_in_hz = freqs)\n",
    "proc.method_to_combine_horizontals = 'geometric_mean'\n",
    "print('-'*60)\n",
    "print('Processing Summary for Traditional HVSR')\n",
    "print(\"-\"*60)\n",
    "proc.psummary()\n",
    "\n",
    "# Processing for single-azimuth HVSR (east)\n",
    "proc_east = settings.HvsrTraditionalSingleAzimuthProcessingSettings()\n",
    "proc_east.window_type_and_width = ('tukey', 0.2)\n",
    "proc_east.smoothing = dict(operator = 'konno_and_ohmachi',\n",
    "                           bandwidth = 40,\n",
    "                           center_frequencies_in_hz = freqs)\n",
    "proc_east.azimuth_in_degrees = 90\n",
    "print('-'*60)\n",
    "print('Processing Summary (East)')\n",
    "print(\"-\"*60)\n",
    "proc_east.psummary()\n",
    "\n",
    "# Window rejection\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_rejection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HVSR_FULL_FROM_ST(stream,preproc,proc):\n",
    "    '''\n",
    "    Feed it a pre-merged Obspy Stream object\n",
    "    for simplicity's sake\n",
    "    '''\n",
    "    # Load waveforms to HVSRPY\n",
    "    source = SeismicRecording3C(\n",
    "        TimeSeries(\n",
    "            stream.select(component='N')[0].data,\n",
    "            stream.select(component='N')[0].stats.delta\n",
    "        ), \n",
    "        TimeSeries(\n",
    "            stream.select(component='E')[0].data,\n",
    "            stream.select(component='E')[0].stats.delta\n",
    "        ), \n",
    "        TimeSeries(\n",
    "            stream.select(component='Z')[0].data,\n",
    "            stream.select(component='Z')[0].stats.delta\n",
    "        )\n",
    "    )\n",
    "    srecords = preprocess(source,preproc)\n",
    "    hvsr = process(srecords,proc)\n",
    "    window_rejection(hvsr,n=n,search_range_in_hz=(1,20))\n",
    "    \n",
    "    return hvsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HVSR_EAST_FROM_ST(stream, preproc, proc):\n",
    "    '''\n",
    "    Feed it a pre-merged Obspy Stream object\n",
    "    for simplicity's sake\n",
    "    '''\n",
    "    # Load waveforms to HVSRPY\n",
    "    source = SeismicRecording3C(\n",
    "        TimeSeries(\n",
    "            stream.select(component='E')[0].data,\n",
    "            stream.select(component='E')[0].stats.delta\n",
    "        ),\n",
    "        TimeSeries(\n",
    "            stream.select(component='E')[0].data,\n",
    "            stream.select(component='E')[0].stats.delta\n",
    "        ),\n",
    "        TimeSeries(\n",
    "            stream.select(component='Z')[0].data,\n",
    "            stream.select(component='Z')[0].stats.delta\n",
    "        )\n",
    "    )\n",
    "    srecords = preprocess(source, preproc)\n",
    "    hvsr = process(srecords, proc)\n",
    "    window_rejection(hvsr, n=n, search_range_in_hz=(1,20))\n",
    "\n",
    "    return hvsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetimedayparser(utcdatetime):\n",
    "    year = utcdatetime.year\n",
    "    month = utcdatetime.month\n",
    "    day = utcdatetime.day\n",
    "    return f\"{year}-{month}-{day}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptime = UTCDateTime(2015,1,1)\n",
    "\n",
    "totaldays = 365\n",
    "\n",
    "days = []\n",
    "dates = []\n",
    "mpldates = []\n",
    "curves_full = []\n",
    "curves_east = []\n",
    "\n",
    "avgamps_Z = []\n",
    "\n",
    "peak_f0_freqs_full = []\n",
    "peak_f0_amps_full = []\n",
    "peak_f0_freqs_east = []\n",
    "peak_f0_amps_east = []\n",
    "\n",
    "mean_f0_freqs_full = []\n",
    "mean_f0_amps_full = []\n",
    "mean_f0_freqs_east = []  \n",
    "mean_f0_amps_east = []  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.sds_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = client.get_waveforms(net, sta, loc, cha, ptime, ptime+600)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(totaldays)):\n",
    "    try:\n",
    "        stime = ptime + i * 86400\n",
    "        etime = stime + 86400\n",
    "        day_julian = i \n",
    "        # Read waveforms\n",
    "        st = client.get_waveforms(net, sta, loc, cha, stime, etime)\n",
    "        st.merge(fill_value = 0)\n",
    "        st.remove_sensitivity(inventory=inv)\n",
    "        st.detrend('linear')\n",
    "        st.filter('highpass',freq=1)\n",
    "        ampdata = np.mean(np.abs(st.select(component='Z')[0].data))\n",
    "        # # Load waveforms to HVSRPY\n",
    "        hv_full = HVSR_FULL_FROM_ST(st,preproc,proc)\n",
    "        hv_east = HVSR_EAST_FROM_ST(st,preproc,proc)\n",
    "\n",
    "        curve_full = hv_full.mean_curve()\n",
    "        curves_full.append(curve_full)\n",
    "        curve_east = hv_east.mean_curve()\n",
    "        curves_east.append(curve_east)\n",
    "\n",
    "\n",
    "        days.append(day_julian)\n",
    "        dates.append(stime)\n",
    "        mpldates.append(stime.matplotlib_date)\n",
    "        avgamps_Z.append(ampdata)\n",
    "\n",
    "\n",
    "        peak_full_f, peak_full_a = hv_full.mean_curve_peak()\n",
    "        peak_east_f, peak_east_a = hv_east.mean_curve_peak()\n",
    "\n",
    "        peak_f0_freqs_full.append(peak_full_f)\n",
    "        peak_f0_amps_full.append(peak_full_a)\n",
    "        peak_f0_freqs_east.append(peak_east_f)\n",
    "        peak_f0_amps_east.append(peak_east_a)\n",
    "\n",
    "        mean_full_f = hv_full.mean_fn_frequency()\n",
    "        mean_full_a = hv_full.mean_fn_amplitude()\n",
    "        mean_east_f = hv_east.mean_fn_frequency()\n",
    "        mean_east_a = hv_east.mean_fn_amplitude()\n",
    "\n",
    "        mean_f0_freqs_full.append(mean_full_f)\n",
    "        mean_f0_amps_full.append(mean_full_a)\n",
    "        mean_f0_freqs_east.append(mean_east_f)\n",
    "        mean_f0_amps_east.append(mean_east_a)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "plotdates = np.array(dates).astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hv = {'day':days,'date':dates,'mpldate':mpldates,'curves_east':curves_east,'curves_full':curves_full,\n",
    "        'peak_east_f':peak_f0_freqs_east,'peak_east_a':peak_f0_amps_east,\n",
    "        'peak_full_f':peak_f0_freqs_full,'peak_full_a':peak_f0_amps_full,\n",
    "        'mean_east_f':mean_f0_freqs_east,'mean_east_a':mean_f0_amps_east,\n",
    "        'mean_full_f':mean_f0_freqs_full,'mean_full_a':mean_f0_amps_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv = pd.DataFrame(data=d_hv)\n",
    "df_hv.to_json('hvsr_colima_24h.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curve in curves_east:\n",
    "    plt.plot(freqs,curve,linewidth=0.1,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
